{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644a4ac9",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d131e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, sampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a31b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../Data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e85343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8988ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7c55a",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d10db0",
   "metadata": {},
   "source": [
    "We can see that the dataset has 'timestamp' variable, which is not really a usefull feature when doing recomendations, thus we can drop this column enterly.\n",
    "\n",
    "After doing this we will be left with userId, movieId, and ratings, these are the only 3 features we will need for our Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a02c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     0\n",
       "movieId    0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's see if there are any missing values in the dataset\n",
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d3bf4",
   "metadata": {},
   "source": [
    "## Preprocessing for Collaborative Filtering\n",
    "\n",
    "Since there are no null values in the dataset, we can continue with the dataset without any issues\n",
    "\n",
    "Now it's time to preprocess the data for the 0-centered cosine, since that is the type of similartiy metric used for Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98cb1f",
   "metadata": {},
   "source": [
    "Being a huge dataset, it will be difficult to preform calculations on this dataset. Thus we will be reducing the size of the datase. So we can sample the dataset to only use 10% of actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94a908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ratings = ratings.sample(frac=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a97338",
   "metadata": {},
   "source": [
    "After that, let's filter out the data with users with number ratings less than 50, and items with number of ratings less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ddf9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17269281</th>\n",
       "      <td>119436</td>\n",
       "      <td>71579</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233670</th>\n",
       "      <td>49921</td>\n",
       "      <td>1196</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828053</th>\n",
       "      <td>12340</td>\n",
       "      <td>193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168558</th>\n",
       "      <td>14684</td>\n",
       "      <td>91630</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667035</th>\n",
       "      <td>129238</td>\n",
       "      <td>2407</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982976</th>\n",
       "      <td>34268</td>\n",
       "      <td>3578</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19589773</th>\n",
       "      <td>135597</td>\n",
       "      <td>2440</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864255</th>\n",
       "      <td>75124</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576560</th>\n",
       "      <td>52225</td>\n",
       "      <td>4308</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780473</th>\n",
       "      <td>60669</td>\n",
       "      <td>1343</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2972414 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "17269281  119436    71579     5.0\n",
       "7233670    49921     1196     5.0\n",
       "1828053    12340      193     2.0\n",
       "2168558    14684    91630     4.5\n",
       "18667035  129238     2407     2.5\n",
       "...          ...      ...     ...\n",
       "4982976    34268     3578     3.5\n",
       "19589773  135597     2440     4.5\n",
       "10864255   75124       19     1.0\n",
       "7576560    52225     4308     5.0\n",
       "8780473    60669     1343     3.5\n",
       "\n",
       "[2972414 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_ratings.groupby('userId').filter(lambda x: len(x) >= 50)\n",
    "sampled_ratings.groupby('movieId').filter(lambda x: len(x) >= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20e09b",
   "metadata": {},
   "source": [
    "## Create User-Item embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2693e",
   "metadata": {},
   "source": [
    "Create a Class to process the data and access it in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b0abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = df['userId'].cat.codes.values\n",
    "        self.items = df['movieId'].cat.codes.values\n",
    "        self.ratings = df['rating'].values.astype(np.float32)\n",
    "        mean_ratings_by_users = df.groupby('userId').rating.transform(lambda x: x.mean())\n",
    "        self.ratings -= mean_ratings_by_users.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = sampled_ratings.userId.nunique()\n",
    "num_items = sampled_ratings.movieId.nunique()\n",
    "embedding_size = 512 ## Embedding size is a hyperparameter, start of small, and increase gradualy\n",
    "\n",
    "## Set up hyperparameters for making dataloaders\n",
    "valid_size = 0.2\n",
    "batch_size = 2000\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cf2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use RatingsDataset class to get 0-centered data\n",
    "sampled_ratings['userId'] = sampled_ratings.userId.astype('category')\n",
    "sampled_ratings['movieId'] = sampled_ratings.movieId.astype('category')\n",
    "\n",
    "## Create the ratings dataset and split into training and test sets\n",
    "dataset = RatingsDataset(sampled_ratings)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e3fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create validation dataset\n",
    "indices = list(range(train_size))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*train_size))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c6433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Random Samples for traning and validation datasets\n",
    "train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = sampler.SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc06c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler,\n",
    "                          num_workers=num_workers, batch_size=batch_size)\n",
    "valid_loader = DataLoader(train_dataset, sampler=valid_sampler, \n",
    "                          num_workers=num_workers, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da467fa",
   "metadata": {},
   "source": [
    "### Visualize the batches of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa72450",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "user, item, rating = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8a9140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 48786, movie 2385, rating 0.0625\n",
      "User 92981, movie 3467, rating 0.837837815284729\n",
      "User 55882, movie 43, rating -1.5192307233810425\n",
      "User 132490, movie 1604, rating -1.75\n",
      "User 86324, movie 315, rating 0.75\n",
      "User 21075, movie 504, rating 0.4699999988079071\n",
      "User 99416, movie 2699, rating 0.2222222238779068\n",
      "User 9544, movie 257, rating -1.5\n",
      "User 27331, movie 2008, rating -0.1428571492433548\n",
      "User 104192, movie 1382, rating 1.5921788215637207\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(f\"User {user[idx]}, movie {item[idx]}, rating {rating[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d133b",
   "metadata": {},
   "source": [
    "# Create the Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ddacbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size):\n",
    "        super(CFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size*2, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        ## Create a item and user embedding vector, and then concatinate them to create a user-item embedding\n",
    "        user_embedd = self.user_embedding(user.long())\n",
    "        item_embedd = self.item_embedding(item.long())\n",
    "        x = torch.cat([user_embedd, item_embedd], dim=-1)\n",
    "        ## Pass through the fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfdfd3",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b6d6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "803be032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# Initialize Model\n",
    "model = CFModel(num_users, num_items, embedding_size)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.834749 \tValidation Loss: 0.825189\n",
      "Validation loss decreased (inf --> 0.825189).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        user, item, rating = data\n",
    "        output = model(user.to(device), item.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, rating.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    for data in valid_loader:\n",
    "        user, item, rating = data\n",
    "        output = model(user.to(device), item.to(device))\n",
    "        loss = criterion(output.to(device), rating.to(device))\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(valid_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), \"model.cf.pt\")\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410ffde",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc57d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved model\n",
    "model.load_state_dict(torch.load(\"model.cf.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c56a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "acc = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for user, item, rating in test_loader:\n",
    "        output = model(user, item) \n",
    "        loss = criterion(output, rating)\n",
    "#         acc.append(accuracy_score(output, rating))\n",
    "        test_loss += loss.item()\n",
    "print('Test Loss: %.4f \\tAccuracy: %.4f' % ((test_loss/len(test_loader)), (np.mean(acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc664284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
