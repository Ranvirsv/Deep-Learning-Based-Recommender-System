{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644a4ac9",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d131e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, sampler\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a31b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../Data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e85343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8988ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7c55a",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d10db0",
   "metadata": {},
   "source": [
    "We can see that the dataset has 'timestamp' variable, which is not really a usefull feature when doing recomendations, thus we can drop this column enterly.\n",
    "\n",
    "After doing this we will be left with userId, movieId, and ratings, these are the only 3 features we will need for our Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a02c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     0\n",
       "movieId    0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's see if there are any missing values in the dataset\n",
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d3bf4",
   "metadata": {},
   "source": [
    "## Preprocessing for Collaborative Filtering\n",
    "\n",
    "Since there are no null values in the dataset, we can continue with the dataset without any issues\n",
    "\n",
    "Now it's time to preprocess the data for the 0-centered cosine, since that is the type of similartiy metric used for Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98cb1f",
   "metadata": {},
   "source": [
    "Being a huge dataset, it will be difficult to preform calculations on this dataset. Thus we will be reducing the size of the datase. So we can sample the dataset to only use 10% of actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94a908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ratings = ratings.sample(frac=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a97338",
   "metadata": {},
   "source": [
    "After that, let's filter out the data with users with number ratings less than 50, and items with number of ratings less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ddf9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17269281</th>\n",
       "      <td>119436</td>\n",
       "      <td>71579</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233670</th>\n",
       "      <td>49921</td>\n",
       "      <td>1196</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828053</th>\n",
       "      <td>12340</td>\n",
       "      <td>193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168558</th>\n",
       "      <td>14684</td>\n",
       "      <td>91630</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667035</th>\n",
       "      <td>129238</td>\n",
       "      <td>2407</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982976</th>\n",
       "      <td>34268</td>\n",
       "      <td>3578</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19589773</th>\n",
       "      <td>135597</td>\n",
       "      <td>2440</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864255</th>\n",
       "      <td>75124</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576560</th>\n",
       "      <td>52225</td>\n",
       "      <td>4308</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780473</th>\n",
       "      <td>60669</td>\n",
       "      <td>1343</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2972414 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "17269281  119436    71579     5.0\n",
       "7233670    49921     1196     5.0\n",
       "1828053    12340      193     2.0\n",
       "2168558    14684    91630     4.5\n",
       "18667035  129238     2407     2.5\n",
       "...          ...      ...     ...\n",
       "4982976    34268     3578     3.5\n",
       "19589773  135597     2440     4.5\n",
       "10864255   75124       19     1.0\n",
       "7576560    52225     4308     5.0\n",
       "8780473    60669     1343     3.5\n",
       "\n",
       "[2972414 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_ratings.groupby('userId').filter(lambda x: len(x) >= 50)\n",
    "sampled_ratings.groupby('movieId').filter(lambda x: len(x) >= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20e09b",
   "metadata": {},
   "source": [
    "## Create User-Item embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2693e",
   "metadata": {},
   "source": [
    "Create a Class to process the data and access it in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b0abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = df['userId'].cat.codes.values\n",
    "        self.items = df['movieId'].cat.codes.values\n",
    "        self.ratings = df['rating'].values.astype(np.float32)\n",
    "        mean_ratings_by_users = df.groupby('userId').rating.transform(lambda x: x.mean())\n",
    "        self.ratings -= mean_ratings_by_users.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = sampled_ratings.userId.nunique()\n",
    "num_items = sampled_ratings.movieId.nunique()\n",
    "embedding_size = 8 ## Embedding size is a hyperparameter, start of small, and increase gradualy\n",
    "\n",
    "## Set up hyperparameters for making dataloaders\n",
    "valid_size = 0.2\n",
    "batch_size = 4000\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cf2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use RatingsDataset class to get 0-centered data\n",
    "sampled_ratings['userId'] = sampled_ratings.userId.astype('category')\n",
    "sampled_ratings['movieId'] = sampled_ratings.movieId.astype('category')\n",
    "\n",
    "## Create the ratings dataset and split into training and test sets\n",
    "dataset = RatingsDataset(sampled_ratings)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e3fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create validation dataset\n",
    "indices = list(range(train_size))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*train_size))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c6433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Random Samples for traning and validation datasets\n",
    "train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = sampler.SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc06c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler,\n",
    "                          num_workers=num_workers, batch_size=batch_size)\n",
    "valid_loader = DataLoader(train_dataset, sampler=valid_sampler, \n",
    "                          num_workers=num_workers, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da467fa",
   "metadata": {},
   "source": [
    "### Visualize the batches of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa72450",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "user, item, rating = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8a9140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 112256, movie 3902, rating -0.30000001192092896\n",
      "User 113880, movie 4152, rating -1.1666666269302368\n",
      "User 62253, movie 2526, rating -0.40909090638160706\n",
      "User 75000, movie 3861, rating 0.09322033822536469\n",
      "User 93908, movie 5887, rating -0.4280303120613098\n",
      "User 26863, movie 2387, rating 0.692307710647583\n",
      "User 91797, movie 11555, rating -0.04901960864663124\n",
      "User 74123, movie 588, rating -0.2857142984867096\n",
      "User 117278, movie 2667, rating -0.8636363744735718\n",
      "User 36099, movie 14888, rating 0.6567164063453674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (25, 4))\n",
    "\n",
    "for idx in range(10):\n",
    "    print(f\"User {user[idx]}, movie {item[idx]}, rating {rating[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d133b",
   "metadata": {},
   "source": [
    "# Create the Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ddacbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size):\n",
    "        super(CFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size*2, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        ## Create a item and user embedding vector, and then concatinate them to create a user-item embedding\n",
    "        user_embedd = self.user_embedding(user.long())\n",
    "        item_embedd = self.item_embedding(item.long())\n",
    "        x = torch.cat([user_embedd, item_embedd], dim=-1)\n",
    "        ## Pass through the fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfdfd3",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "803be032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# Initialize Model\n",
    "model = CFModel(num_users, num_items, embedding_size)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e386d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: -93.399993 \tValidation Loss: -20.855145\n",
      "Validation loss decreased (inf --> -20.855145).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.002579 \tValidation Loss: -21.055757\n",
      "Validation loss decreased (-20.855145 --> -21.055757).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.878166 \tValidation Loss: -20.827935\n",
      "Epoch: 4 \tTraining Loss: 4.908180 \tValidation Loss: -20.850258\n",
      "Epoch: 5 \tTraining Loss: 4.903585 \tValidation Loss: -20.809316\n",
      "Epoch: 6 \tTraining Loss: 4.898990 \tValidation Loss: -20.932398\n",
      "Epoch: 7 \tTraining Loss: 4.914234 \tValidation Loss: -20.870354\n",
      "Epoch: 8 \tTraining Loss: 4.831533 \tValidation Loss: -20.752119\n",
      "Epoch: 9 \tTraining Loss: 4.804956 \tValidation Loss: -20.687696\n",
      "Epoch: 10 \tTraining Loss: 4.915619 \tValidation Loss: -20.744834\n",
      "Epoch: 11 \tTraining Loss: 4.840008 \tValidation Loss: -20.868812\n",
      "Epoch: 12 \tTraining Loss: 4.923548 \tValidation Loss: -20.878661\n",
      "Epoch: 13 \tTraining Loss: 4.931736 \tValidation Loss: -20.708335\n",
      "Epoch: 14 \tTraining Loss: 4.970632 \tValidation Loss: -20.646142\n",
      "Epoch: 15 \tTraining Loss: 4.882635 \tValidation Loss: -20.540922\n",
      "Epoch: 16 \tTraining Loss: 4.872821 \tValidation Loss: -20.943582\n",
      "Epoch: 17 \tTraining Loss: 4.906194 \tValidation Loss: -20.950177\n",
      "Epoch: 18 \tTraining Loss: 4.891482 \tValidation Loss: -20.595798\n",
      "Epoch: 19 \tTraining Loss: 4.974114 \tValidation Loss: -20.643272\n",
      "Epoch: 20 \tTraining Loss: 4.921132 \tValidation Loss: -21.079085\n",
      "Validation loss decreased (-21.055757 --> -21.079085).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 4.807622 \tValidation Loss: -20.732447\n",
      "Epoch: 22 \tTraining Loss: 4.921322 \tValidation Loss: -20.822347\n",
      "Epoch: 23 \tTraining Loss: 4.926200 \tValidation Loss: -20.910807\n",
      "Epoch: 24 \tTraining Loss: 4.853947 \tValidation Loss: -20.968633\n",
      "Epoch: 25 \tTraining Loss: 4.964782 \tValidation Loss: -20.779775\n",
      "Epoch: 26 \tTraining Loss: 4.839806 \tValidation Loss: -20.813215\n",
      "Epoch: 27 \tTraining Loss: 4.922261 \tValidation Loss: -20.923953\n",
      "Epoch: 28 \tTraining Loss: 4.859028 \tValidation Loss: -20.760672\n",
      "Epoch: 29 \tTraining Loss: 4.975364 \tValidation Loss: -20.614855\n",
      "Epoch: 30 \tTraining Loss: 4.909415 \tValidation Loss: -20.931154\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        user, item, rating = data\n",
    "        output = model(user, item)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    for data in valid_loader:\n",
    "        user, item, rating = data\n",
    "        output = model(user, item)\n",
    "        loss = criterion(output, rating)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(valid_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), \"model.cf.pt\")\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410ffde",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dc57d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the saved model\n",
    "model.load_state_dict(torch.load(\"model.cf.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c56a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0822\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for user, item, rating in test_loader:\n",
    "        output = model(user, item) \n",
    "        loss = criterion(output, rating)\n",
    "        test_loss += loss.item()\n",
    "print('Test Loss: %.4f' % (test_loss/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc664284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
