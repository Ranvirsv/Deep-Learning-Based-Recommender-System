{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644a4ac9",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d131e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a31b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../Data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e85343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8988ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7c55a",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d10db0",
   "metadata": {},
   "source": [
    "We can see that the dataset has 'timestamp' variable, which is not really a usefull feature when doing recomendations, thus we can drop this column enterly.\n",
    "\n",
    "After doing this we will be left with userId, movieId, and ratings, these are the only 3 features we will need for our Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a02c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     0\n",
       "movieId    0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's see if there are any missing values in the dataset\n",
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d3bf4",
   "metadata": {},
   "source": [
    "## Preprocessing for Collaborative Filtering\n",
    "\n",
    "Since there are no null values in the dataset, we can continue with the dataset without any issues\n",
    "\n",
    "Now it's time to preprocess the data for the 0-centered cosine, since that is the type of similartiy metric used for Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98cb1f",
   "metadata": {},
   "source": [
    "Being a huge dataset, it will be difficult to preform calculations on this dataset. Thus we will be reducing the size of the datase. So we can sample the dataset to only use 10% of actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94a908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ratings = ratings.sample(frac=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a97338",
   "metadata": {},
   "source": [
    "After that, let's filter out the data with users with number ratings less than 50, and items with number of ratings less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ddf9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17269281</th>\n",
       "      <td>119436</td>\n",
       "      <td>71579</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233670</th>\n",
       "      <td>49921</td>\n",
       "      <td>1196</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828053</th>\n",
       "      <td>12340</td>\n",
       "      <td>193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168558</th>\n",
       "      <td>14684</td>\n",
       "      <td>91630</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667035</th>\n",
       "      <td>129238</td>\n",
       "      <td>2407</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982976</th>\n",
       "      <td>34268</td>\n",
       "      <td>3578</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19589773</th>\n",
       "      <td>135597</td>\n",
       "      <td>2440</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864255</th>\n",
       "      <td>75124</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576560</th>\n",
       "      <td>52225</td>\n",
       "      <td>4308</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780473</th>\n",
       "      <td>60669</td>\n",
       "      <td>1343</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2972414 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "17269281  119436    71579     5.0\n",
       "7233670    49921     1196     5.0\n",
       "1828053    12340      193     2.0\n",
       "2168558    14684    91630     4.5\n",
       "18667035  129238     2407     2.5\n",
       "...          ...      ...     ...\n",
       "4982976    34268     3578     3.5\n",
       "19589773  135597     2440     4.5\n",
       "10864255   75124       19     1.0\n",
       "7576560    52225     4308     5.0\n",
       "8780473    60669     1343     3.5\n",
       "\n",
       "[2972414 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_ratings.groupby('userId').filter(lambda x: len(x) >= 50)\n",
    "sampled_ratings.groupby('movieId').filter(lambda x: len(x) >= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20e09b",
   "metadata": {},
   "source": [
    "## Create User-Item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = sampled_ratings.userId.nunique()\n",
    "num_items = sampled_ratings.movieId.nunique()\n",
    "embedding_size = 512 ## Embedding size is a hyperparameter, start of small, and increase gradualy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2693e",
   "metadata": {},
   "source": [
    "Create a Class to process the data and access it in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b0abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = df['userId'].cat.codes.values\n",
    "        self.items = df['movieId'].cat.codes.values\n",
    "        self.ratings = df['rating'].values.astype(np.float32)\n",
    "        mean_ratings_by_users = df.groupby('userId').rating.transform(lambda x: x.mean())\n",
    "        self.ratings -= mean_ratings_by_users.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cf2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4000\n",
    "\n",
    "## Let's use RatingsDataset class to get 0-centered data\n",
    "sampled_ratings['userId'] = sampled_ratings.userId.astype('category')\n",
    "sampled_ratings['movieId'] = sampled_ratings.movieId.astype('category')\n",
    "\n",
    "# Create the ratings dataset and split into training and test sets\n",
    "dataset = RatingsDataset(sampled_ratings)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9accf1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99856, 15837, -0.45588234)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d133b",
   "metadata": {},
   "source": [
    "# Create the Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ddacbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size):\n",
    "        super(CFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size*2, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        ## Create a item and user embedding vector, and then concatinate them to create a user-item embedding\n",
    "        user_embedd = self.user_embedding(user.long())\n",
    "        item_embedd = self.item_embedding(item.long())\n",
    "        x = torch.cat([user_embedd, item_embedd], dim=-1)\n",
    "        ## Pass through the fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803be032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "\n",
    "# Initialize Model\n",
    "model = CFModel(num_users, num_items, embedding_size)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e386d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 30, Traning loss: 0.8323\n",
      "Epoch 2 of 30, Traning loss: 0.8103\n",
      "Epoch 3 of 30, Traning loss: 0.7970\n",
      "Epoch 4 of 30, Traning loss: 0.7866\n",
      "Epoch 5 of 30, Traning loss: 0.7772\n",
      "Epoch 6 of 30, Traning loss: 0.7699\n",
      "Epoch 7 of 30, Traning loss: 0.7630\n",
      "Epoch 8 of 30, Traning loss: 0.7575\n",
      "Epoch 9 of 30, Traning loss: 0.7541\n",
      "Epoch 10 of 30, Traning loss: 0.7498\n",
      "Epoch 11 of 30, Traning loss: 0.7462\n",
      "Epoch 12 of 30, Traning loss: 0.7432\n",
      "Epoch 13 of 30, Traning loss: 0.7421\n",
      "Epoch 14 of 30, Traning loss: 0.7391\n",
      "Epoch 15 of 30, Traning loss: 0.7378\n",
      "Epoch 16 of 30, Traning loss: 0.7363\n",
      "Epoch 17 of 30, Traning loss: 0.7343\n",
      "Epoch 18 of 30, Traning loss: 0.7331\n",
      "Epoch 19 of 30, Traning loss: 0.7320\n",
      "Epoch 20 of 30, Traning loss: 0.7304\n",
      "Epoch 21 of 30, Traning loss: 0.7298\n",
      "Epoch 22 of 30, Traning loss: 0.7283\n",
      "Epoch 23 of 30, Traning loss: 0.7270\n",
      "Epoch 24 of 30, Traning loss: 0.7265\n",
      "Epoch 25 of 30, Traning loss: 0.7255\n",
      "Epoch 26 of 30, Traning loss: 0.7251\n",
      "Epoch 27 of 30, Traning loss: 0.7341\n",
      "Epoch 28 of 30, Traning loss: 0.7298\n",
      "Epoch 29 of 30, Traning loss: 0.7281\n",
      "Epoch 30 of 30, Traning loss: 0.7270\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        user, item, rating = data\n",
    "        output = model(user, item)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    traning_loss = running_loss/len(train_loader)\n",
    "    print('Epoch %d of %d, Traning loss: %.4f' % (epoch+1, epochs, traning_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c56a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 129.1781\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for user, item, rating in test_loader:\n",
    "        output = model(user, item) \n",
    "        loss = criterion(output, rating)\n",
    "        test_loss += loss.item()\n",
    "print('Test Loss: %.4f' % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc664284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
